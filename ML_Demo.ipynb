{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of machine learning models\n",
    "\n",
    "This notebook tests the effectiveness of a variety of machine learning models on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss, log_loss, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_79 = pd.read_csv('data/cohort79_Jun8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_97 = pd.read_csv('data/cohort97_Jun8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([cohort_79, cohort_97], sort=False)\n",
    "merged_data.drop(merged_data[merged_data[\"adjusted_income\"] <= 1000].index, inplace=True)\n",
    "merged_data.fillna(0, inplace=True)\n",
    "\n",
    "predictors = list(merged_data.columns)\n",
    "vars_to_drop = [\"case_id\",\"urban_or_rural\",\"family_size\", \"sample_id\", \"year\", \"shock\", \"region\", \"highest_grade\", \"industry\", \"occupation\", \"Unnamed: 0\",'marital_status', 'race', \"region_1\", \"region_2\", \"region_3\", \"region_4\", \"work_kind_limited\", \"work_amount_limited\"]\n",
    "for var in vars_to_drop:\n",
    "    predictors.remove(var)\n",
    "    \n",
    "X = merged_data[predictors]\n",
    "y = np.ravel(merged_data[\"shock\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X, y, estimator, n_folds, scale=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\" \n",
    "    \n",
    "    kf = KFold(n_splits = n_folds)\n",
    "    f1_scores = []\n",
    "    brier_scores = []\n",
    "    log_loss_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        if scale:\n",
    "            # The standard scaler will raise a warning about variable types. To suppress those for the moment...    \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                scaler = StandardScaler().fit(X_train)\n",
    "                X_train = scaler.transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "\n",
    "        estimator.fit(X_train, y_train, **kwargs)  \n",
    "\n",
    "        expected  = y_test\n",
    "        predicted = estimator.predict(X_test)\n",
    "        predicted_proba = estimator.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        f1_scores.append(f1_score(expected, predicted, average=\"weighted\"))\n",
    "        brier_scores.append(brier_score_loss(expected, predicted_proba))\n",
    "        log_loss_scores.append(log_loss(expected, predicted_proba))\n",
    "    \n",
    "    print(\"Model: {}\".format(estimator.__class__.__name__))\n",
    "    print(\"F1 score (higher is better): {:.03f}\".format(np.mean(f1_scores)))\n",
    "    print(\"Brier score loss (lower is better): {:.03f}\".format(np.mean(brier_scores)))\n",
    "    print(\"Log loss (lower is better): {:.03f}\\n\".format(np.mean(log_loss_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DummyPredictor\n",
      "F1 score (higher is better): 0.662\n",
      "Brier score loss (lower is better): 0.180\n",
      "Log loss (lower is better): 0.546\n",
      "\n",
      "Model: SGDClassifier\n",
      "F1 score (higher is better): 0.694\n",
      "Brier score loss (lower is better): 0.175\n",
      "Log loss (lower is better): 0.559\n",
      "\n",
      "Model: LogisticRegression\n",
      "F1 score (higher is better): 0.693\n",
      "Brier score loss (lower is better): 0.171\n",
      "Log loss (lower is better): 0.521\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "F1 score (higher is better): 0.679\n",
      "Brier score loss (lower is better): 0.169\n",
      "Log loss (lower is better): 0.517\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "F1 score (higher is better): 0.691\n",
      "Brier score loss (lower is better): 0.171\n",
      "Log loss (lower is better): 0.520\n",
      "\n",
      "Model: BaggingClassifier\n",
      "F1 score (higher is better): 0.696\n",
      "Brier score loss (lower is better): 0.192\n",
      "Log loss (lower is better): 1.090\n",
      "\n",
      "Model: GaussianNB\n",
      "F1 score (higher is better): 0.603\n",
      "Brier score loss (lower is better): 0.359\n",
      "Log loss (lower is better): 3.394\n",
      "\n",
      "Model: MLPClassifier\n",
      "F1 score (higher is better): 0.708\n",
      "Brier score loss (lower is better): 0.184\n",
      "Log loss (lower is better): 0.563\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "F1 score (higher is better): 0.700\n",
      "Brier score loss (lower is better): 0.167\n",
      "Log loss (lower is better): 0.511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_predictions = np.full((len(X), 1), merged_data[\"shock\"].median())\n",
    "dummy_probs = np.full((len(X), 1), merged_data[\"shock\"].mean())\n",
    "brier_skill_ref = brier_score_loss(y, dummy_probs)\n",
    "\n",
    "print(\"Model: DummyPredictor\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(\"F1 score (higher is better): {:.03f}\".format(f1_score(y, dummy_predictions, average=\"weighted\")))\n",
    "print(\"Brier score loss (lower is better): {:.03f}\".format(brier_skill_ref))\n",
    "print(\"Log loss (lower is better): {:.03f}\\n\".format(log_loss(y, dummy_probs)))\n",
    "\n",
    "models = [\n",
    "    SGDClassifier(loss=\"log\", max_iter=1000, tol=.001),\n",
    "    LogisticRegression(solver=\"lbfgs\"),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    BaggingClassifier(),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(hidden_layer_sizes=(71,), activation='tanh', alpha=.001),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=.3, max_features=30, max_depth=4, min_samples_leaf=75),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    score_model(X, y, model, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
